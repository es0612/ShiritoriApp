import Foundation
import Speech
import AVFoundation
import Observation

#if os(iOS)
import UIKit
#endif

/// éŸ³å£°èªè­˜ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
@Observable
public class SpeechRecognitionManager: NSObject {
    public private(set) var isRecording = false
    public private(set) var isAvailable = false
    public private(set) var useOnDeviceRecognition = true
    public private(set) var shouldReportPartialResults = true
    
    // å¤±æ•—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ©Ÿèƒ½
    public private(set) var consecutiveFailureCount = 0
    private var failureThreshold = 3
    
    private var audioEngine = AVAudioEngine()
    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private var onTextReceived: ((String) -> Void)?
    
    // éŸ³å£°èªè­˜ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    private var startTime: Date?
    private var lastPartialResult: String = ""
    
    public override init() {
        super.init()
        AppLogger.shared.debug("SpeechRecognitionManageråˆæœŸåŒ–é–‹å§‹")
        
        // æ—¥æœ¬èªéŸ³å£°èªè­˜ã‚’åˆæœŸåŒ–
        speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ja-JP"))
        speechRecognizer?.delegate = self
        
        // éŸ³å£°èªè­˜ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ç¢ºèª
        updateAvailability()
        
        AppLogger.shared.info("SpeechRecognitionManageråˆæœŸåŒ–å®Œäº†: åˆ©ç”¨å¯èƒ½=\(isAvailable), ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹=\(useOnDeviceRecognition)")
    }
    
    /// éŸ³å£°èªè­˜è¨­å®šã‚’æ›´æ–°
    public func updateSettings(useOnDeviceRecognition: Bool, shouldReportPartialResults: Bool) {
        AppLogger.shared.debug("éŸ³å£°èªè­˜è¨­å®šæ›´æ–°: ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹=\(useOnDeviceRecognition), ä¸­é–“çµæœ=\(shouldReportPartialResults)")
        
        self.useOnDeviceRecognition = useOnDeviceRecognition
        self.shouldReportPartialResults = shouldReportPartialResults
        
        AppLogger.shared.info("éŸ³å£°èªè­˜è¨­å®šæ›´æ–°å®Œäº†")
    }
    
    // MARK: - å¤±æ•—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ©Ÿèƒ½
    
    /// é€£ç¶šå¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ 
    public func incrementFailureCount() {
        consecutiveFailureCount += 1
        AppLogger.shared.debug("éŸ³å£°èªè­˜å¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å¢—åŠ : \(consecutiveFailureCount)/\(failureThreshold)")
    }
    
    /// é€£ç¶šå¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
    public func resetFailureCount() {
        consecutiveFailureCount = 0
        AppLogger.shared.debug("éŸ³å£°èªè­˜å¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒªã‚»ãƒƒãƒˆ")
    }
    
    /// å¤±æ•—é–¾å€¤ã«é”ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
    public func hasReachedFailureThreshold() -> Bool {
        return consecutiveFailureCount >= failureThreshold
    }
    
    /// éŸ³å£°èªè­˜æˆåŠŸã‚’è¨˜éŒ²ï¼ˆå¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆï¼‰
    public func recordRecognitionSuccess() {
        resetFailureCount()
        AppLogger.shared.debug("éŸ³å£°èªè­˜æˆåŠŸã‚’è¨˜éŒ²")
    }
    
    /// å¤±æ•—é–¾å€¤ã‚’è¨­å®š
    public func setFailureThreshold(_ threshold: Int) {
        failureThreshold = max(1, threshold) // æœ€å°1å›
        AppLogger.shared.debug("éŸ³å£°èªè­˜å¤±æ•—é–¾å€¤è¨­å®š: \(failureThreshold)")
    }
    
    /// æ–°ã‚¿ãƒ¼ãƒ³ç”¨ã®åŒ…æ‹¬çš„ãƒªã‚»ãƒƒãƒˆï¼ˆãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼å¤‰æ›´æ™‚ã«ä½¿ç”¨ï¼‰
    public func resetForNewTurn() {
        AppLogger.shared.debug("SpeechRecognitionManager: æ–°ã‚¿ãƒ¼ãƒ³ç”¨ãƒªã‚»ãƒƒãƒˆé–‹å§‹")
        
        // é€²è¡Œä¸­ã®éŒ²éŸ³ã‚’åœæ­¢
        if isRecording {
            AppLogger.shared.info("ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼å¤‰æ›´æ™‚ã«é€²è¡Œä¸­ã®éŒ²éŸ³ã‚’åœæ­¢")
            stopRecording()
        }
        
        // å¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
        resetFailureCount()
        
        // éƒ¨åˆ†çµæœã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’ã‚¯ãƒªã‚¢
        lastPartialResult = ""
        startTime = nil
        
        // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‚ç…§ã‚’ã‚¯ãƒªã‚¢ï¼ˆãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
        onTextReceived = nil
        
        AppLogger.shared.debug("SpeechRecognitionManager: æ–°ã‚¿ãƒ¼ãƒ³ç”¨ãƒªã‚»ãƒƒãƒˆå®Œäº†")
    }
    
    /// éŸ³å£°èªè­˜ã®è¨±å¯ã‚’è¦æ±‚
    public func requestSpeechPermission() async -> Bool {
        AppLogger.shared.debug("éŸ³å£°èªè­˜è¨±å¯è¦æ±‚é–‹å§‹")
        
        // éŸ³å£°èªè­˜è¨±å¯ã®ç¢ºèª
        let speechAuthStatus = await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status)
            }
        }
        
        AppLogger.shared.debug("éŸ³å£°èªè­˜è¨±å¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: \(speechAuthStatus.rawValue)")
        
        // ãƒã‚¤ã‚¯è¨±å¯ã®ç¢ºèª
        let microphoneAuthStatus: Bool
        #if os(iOS)
        microphoneAuthStatus = await withCheckedContinuation { continuation in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
        #else
        // macOSã§ã¯å¸¸ã«trueã‚’è¿”ã™ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        microphoneAuthStatus = true
        #endif
        
        AppLogger.shared.debug("ãƒã‚¤ã‚¯è¨±å¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: \(microphoneAuthStatus)")
        
        let hasPermission = speechAuthStatus == .authorized && microphoneAuthStatus
        AppLogger.shared.info("éŸ³å£°èªè­˜è¨±å¯ç¢ºèªå®Œäº†: è¨±å¯ã‚ã‚Š=\(hasPermission)")
        
        await MainActor.run {
            updateAvailability()
        }
        
        return hasPermission
    }
    
    /// éŸ³å£°èªè­˜ã‚’é–‹å§‹
    public func startRecording(onTextReceived: @escaping (String) -> Void) async {
        AppLogger.shared.debug("éŸ³å£°èªè­˜é–‹å§‹è¦æ±‚")
        
        // æ—¢ã«éŒ²éŸ³ä¸­ã®å ´åˆã¯åœæ­¢
        if isRecording {
            AppLogger.shared.warning("æ—¢ã«éŒ²éŸ³ä¸­ã®ãŸã‚ã€ç¾åœ¨ã®éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã™")
            stopRecording()
        }
        
        self.onTextReceived = onTextReceived
        
        // è¨±å¯ç¢ºèª
        let hasPermission = await requestSpeechPermission()
        guard hasPermission else {
            AppLogger.shared.error("éŸ³å£°èªè­˜é–‹å§‹å¤±æ•—: è¨±å¯ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        }
        
        do {
            try await startRecordingInternal()
            AppLogger.shared.info("éŸ³å£°èªè­˜é–‹å§‹æˆåŠŸ")
        } catch {
            AppLogger.shared.error("éŸ³å£°èªè­˜é–‹å§‹ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)")
        }
    }
    
    /// éŸ³å£°èªè­˜ã‚’åœæ­¢
    public func stopRecording() {
        AppLogger.shared.debug("éŸ³å£°èªè­˜åœæ­¢è¦æ±‚")
        
        let totalDuration = startTime.map { Date().timeIntervalSince($0) } ?? 0
        
        recognitionRequest?.endAudio()
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        
        recognitionTask?.cancel()
        recognitionTask = nil
        recognitionRequest = nil
        
        isRecording = false
        startTime = nil
        
        AppLogger.shared.info("éŸ³å£°èªè­˜åœæ­¢å®Œäº†: ç·éŒ²éŸ³æ™‚é–“=\(String(format: "%.2f", totalDuration))s, æœ€çµ‚çµæœ='\(lastPartialResult)'")
        lastPartialResult = ""
    }
    
    // MARK: - Private Methods
    
    private func updateAvailability() {
        #if os(iOS)
        isAvailable = speechRecognizer?.isAvailable == true &&
                     SFSpeechRecognizer.authorizationStatus() == .authorized &&
                     AVAudioSession.sharedInstance().recordPermission == .granted
        #else
        // macOSã§ã¯éŸ³å£°èªè­˜ã®ã¿ãƒã‚§ãƒƒã‚¯
        isAvailable = speechRecognizer?.isAvailable == true &&
                     SFSpeechRecognizer.authorizationStatus() == .authorized
        #endif
        
        AppLogger.shared.debug("éŸ³å£°èªè­˜åˆ©ç”¨å¯èƒ½æ€§æ›´æ–°: \(isAvailable)")
    }
    
    private func startRecordingInternal() async throws {
        AppLogger.shared.debug("éŸ³å£°èªè­˜å†…éƒ¨å‡¦ç†é–‹å§‹")
        
        #if os(iOS)
        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(.record, mode: .measurement, options: .duckOthers)
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        #endif
        
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            throw SpeechRecognitionError.recognitionRequestCreationFailed
        }
        
        recognitionRequest.shouldReportPartialResults = shouldReportPartialResults
        recognitionRequest.requiresOnDeviceRecognition = useOnDeviceRecognition
        
        // ã—ã‚Šã¨ã‚Šç”¨ã®çŸ­ã„å˜èªèªè­˜ã«æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®š
        if #available(iOS 13.0, *) {
            recognitionRequest.taskHint = .search // çŸ­ã„å˜èªæ¤œç´¢ã«æœ€é©
        }
        
        AppLogger.shared.debug("éŸ³å£°èªè­˜è¨­å®š: ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹=\(useOnDeviceRecognition), ä¸­é–“çµæœ=\(shouldReportPartialResults), ã‚¿ã‚¹ã‚¯ãƒ’ãƒ³ãƒˆ=search")
        
        guard let speechRecognizer = speechRecognizer else {
            throw SpeechRecognitionError.speechRecognizerUnavailable
        }
        
        recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            guard let self = self else { return }
            
            if let result = result {
                let recognizedText = result.bestTranscription.formattedString
                let confidence = result.bestTranscription.segments.first?.confidence ?? 0.0
                let isFinal = result.isFinal
                
                // è©³ç´°ãªéŸ³å£°èªè­˜ãƒ­ã‚°
                let elapsedTime = startTime.map { Date().timeIntervalSince($0) } ?? 0
                AppLogger.shared.debug("éŸ³å£°èªè­˜çµæœ [çµŒéæ™‚é–“: \(String(format: "%.2f", elapsedTime))s]: '\(recognizedText)' (ä¿¡é ¼åº¦: \(String(format: "%.2f", confidence)), ç¢ºå®š: \(isFinal))")
                
                // å€™è£œã®è©³ç´°ãƒ­ã‚°ï¼ˆé–‹ç™ºæ™‚ã®åˆ†æç”¨ï¼‰
                if result.transcriptions.count > 1 {
                    let alternatives = result.transcriptions.prefix(3).map { $0.formattedString }
                    AppLogger.shared.debug("éŸ³å£°èªè­˜å€™è£œ: \(alternatives)")
                }
                
                // éŸ³å£°èªè­˜çµæœã®å“è³ªæ¤œè¨¼
                let qualityResult = self.validateRecognitionQuality(text: recognizedText, confidence: confidence)
                
                if !qualityResult.isValid {
                    AppLogger.shared.warning("éŸ³å£°èªè­˜çµæœãŒå“è³ªåŸºæº–ã‚’æº€ãŸã—ã¾ã›ã‚“: '\(recognizedText)' - \(qualityResult.reason)")
                    
                    // å¤±æ•—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ ï¼ˆç¢ºå®šçµæœã®å ´åˆã®ã¿ï¼‰
                    if isFinal {
                        self.incrementFailureCount()
                    }
                    
                    // å“è³ªåŸºæº–ã‚’æº€ãŸã•ãªã„çµæœã¯é€ä¿¡ã—ãªã„
                    return
                } else if isFinal {
                    // å“è³ªåŸºæº–ã‚’æº€ãŸã™ç¢ºå®šçµæœã®å ´åˆã€æˆåŠŸã‚’è¨˜éŒ²
                    self.recordRecognitionSuccess()
                }
                
                // å‰å›ã®çµæœã¨æ¯”è¼ƒ
                if recognizedText != lastPartialResult {
                    AppLogger.shared.debug("éŸ³å£°èªè­˜çµæœæ›´æ–°: '\(lastPartialResult)' -> '\(recognizedText)'")
                    lastPartialResult = recognizedText
                }
                
                DispatchQueue.main.async {
                    self.onTextReceived?(recognizedText)
                }
            }
            
            if let error = error {
                AppLogger.shared.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)")
                DispatchQueue.main.async {
                    self.stopRecording()
                }
            }
        }
        
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        
        AppLogger.shared.debug("ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¨­å®š: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ=\(recordingFormat.sampleRate), ãƒãƒ£ãƒ³ãƒãƒ«æ•°=\(recordingFormat.channelCount)")
        
        // ã—ã‚Šã¨ã‚Šç”¨ã®çŸ­ã„å˜èªèªè­˜ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
        let bufferSize: AVAudioFrameCount = 512 // å°ã•ã„ãƒãƒƒãƒ•ã‚¡ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‘ä¸Š
        
        inputNode.installTap(onBus: 0, bufferSize: bufferSize, format: recordingFormat) { buffer, _ in
            recognitionRequest.append(buffer)
        }
        
        audioEngine.prepare()
        try audioEngine.start()
        
        startTime = Date()
        lastPartialResult = ""
        isRecording = true
        
        let startTimeString = startTime.map { String(describing: $0) } ?? "nil"
        AppLogger.shared.info("éŸ³å£°èªè­˜é–‹å§‹: é–‹å§‹æ™‚åˆ»=\(startTimeString), ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º=\(bufferSize)")
    }
    
    // MARK: - Quality Validation
    
    /// éŸ³å£°èªè­˜çµæœã®å“è³ªæ¤œè¨¼çµæœ
    private struct RecognitionQualityResult {
        let isValid: Bool
        let reason: String
    }
    
    /// éŸ³å£°èªè­˜çµæœã®å“è³ªã‚’æ¤œè¨¼ã™ã‚‹
    private func validateRecognitionQuality(text: String, confidence: Float) -> RecognitionQualityResult {
        AppLogger.shared.debug("ğŸ” éŸ³å£°èªè­˜å“è³ªæ¤œè¨¼é–‹å§‹: text='\(text)', confidence=\(String(format: "%.3f", confidence))")
        
        // 1. åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        guard !text.isEmpty else {
            AppLogger.shared.debug("âŒ å“è³ªæ¤œè¨¼å¤±æ•—: ç©ºæ–‡å­—")
            return RecognitionQualityResult(isValid: false, reason: "ç©ºæ–‡å­—")
        }
        
        // 2. ä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆç·©å’Œã•ã‚ŒãŸåŸºæº–ï¼‰
        // çŸ­ã„å˜èªã§ã‚‚0.5ä»¥ä¸Šã‚ã‚Œã°è¨±å¯ï¼ˆä»¥å‰ã¯0.7ï¼‰
        let minConfidence: Float = text.count <= 2 ? 0.6 : 0.4  // ã‚ˆã‚Šç·©ã„åŸºæº–
        if confidence < minConfidence {
            AppLogger.shared.debug("âŒ å“è³ªæ¤œè¨¼å¤±æ•—: ä¿¡é ¼åº¦ä¸è¶³ \(String(format: "%.3f", confidence)) < \(minConfidence)")
            return RecognitionQualityResult(isValid: false, reason: "ä¿¡é ¼åº¦ä¸è¶³: \(String(format: "%.2f", confidence)) < \(minConfidence)")
        }
        
        // 3. ä¸è‡ªç„¶ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆç·©å’Œï¼‰
        if hasUnnaturalPatterns(text) {
            AppLogger.shared.debug("âŒ å“è³ªæ¤œè¨¼å¤±æ•—: ä¸è‡ªç„¶ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º")
            return RecognitionQualityResult(isValid: false, reason: "ä¸è‡ªç„¶ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º")
        }
        
        // 4. éã²ã‚‰ãŒãªæ–‡å­—ã®ãƒã‚§ãƒƒã‚¯ï¼ˆä¿®æ­£ï¼‰
        if hasInvalidCharacters(text) {
            AppLogger.shared.debug("âŒ å“è³ªæ¤œè¨¼å¤±æ•—: ç„¡åŠ¹ãªæ–‡å­—ã‚’å«ã‚€")
            return RecognitionQualityResult(isValid: false, reason: "ç„¡åŠ¹ãªæ–‡å­—ã‚’å«ã‚€")
        }
        
        AppLogger.shared.debug("âœ… å“è³ªæ¤œè¨¼æˆåŠŸ: '\(text)'")
        return RecognitionQualityResult(isValid: true, reason: "å“è³ªåŸºæº–é©åˆ")
    }
    
    /// ä¸è‡ªç„¶ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã™ã‚‹
    private func hasUnnaturalPatterns(_ text: String) -> Bool {
        // åŒã˜æ–‡å­—ãƒ»éŸ³ã®éåº¦ãªç¹°ã‚Šè¿”ã—
        if hasExcessiveRepetition(text) {
            return true
        }
        
        // æ„å‘³ã®ãªã„éŸ³ã®çµ„ã¿åˆã‚ã›
        if hasNonsensicalCombinations(text) {
            return true
        }
        
        return false
    }
    
    /// éåº¦ãªæ–‡å­—ç¹°ã‚Šè¿”ã—ã‚’æ¤œå‡º
    private func hasExcessiveRepetition(_ text: String) -> Bool {
        // åŒã˜æ–‡å­—ãŒ4å›ä»¥ä¸Šé€£ç¶š
        let pattern = #"(.)\1{3,}"#
        if text.range(of: pattern, options: .regularExpression) != nil {
            AppLogger.shared.debug("éåº¦ãªæ–‡å­—ç¹°ã‚Šè¿”ã—æ¤œå‡º: \(text)")
            return true
        }
        
        // 2-3æ–‡å­—ã®ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹ï¼šã€ŒãŸã„ããŸã„ããŸã„ãã€ï¼‰
        for length in 2...3 {
            if hasRepeatingSubstring(text, length: length, minRepetitions: 3) {
                AppLogger.shared.debug("\(length)æ–‡å­—ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: \(text)")
                return true
            }
        }
        
        return false
    }
    
    /// æŒ‡å®šã•ã‚ŒãŸé•·ã•ã®éƒ¨åˆ†æ–‡å­—åˆ—ã®ç¹°ã‚Šè¿”ã—ã‚’æ¤œå‡º
    private func hasRepeatingSubstring(_ text: String, length: Int, minRepetitions: Int) -> Bool {
        guard text.count >= length * minRepetitions else { return false }
        
        let substring = String(text.prefix(length))
        var repetitions = 1
        var index = text.index(text.startIndex, offsetBy: length)
        
        while index < text.endIndex && text.distance(from: index, to: text.endIndex) >= length {
            let nextSubstring = String(text[index..<text.index(index, offsetBy: length)])
            if nextSubstring == substring {
                repetitions += 1
                if repetitions >= minRepetitions {
                    return true
                }
            } else {
                break
            }
            index = text.index(index, offsetBy: length)
        }
        
        return false
    }
    
    /// æ„å‘³ã®ãªã„éŸ³ã®çµ„ã¿åˆã‚ã›ã‚’æ¤œå‡º
    private func hasNonsensicalCombinations(_ text: String) -> Bool {
        // ã€Œãµãã€ã€Œãµãƒã€ã€Œãµã‡ã€ã€Œãµã‰ã€ãªã©ã®å¤–æ¥èªéŸ³ãŒä¸è‡ªç„¶ã«çµ„ã¿åˆã‚ã•ã‚Œã¦ã„ã‚‹
        let foreignSounds = ["ãµã", "ãµãƒ", "ãµã‡", "ãµã‰", "ã†ãƒ", "ã†ã‡", "ã†ã‰", "ã¡ã‚ƒ", "ã¡ã‚…", "ã¡ã‡", "ã¡ã‚‡"]
        let foreignSoundCount = foreignSounds.reduce(0) { count, sound in
            count + text.components(separatedBy: sound).count - 1
        }
        
        // å¤–æ¥èªéŸ³ãŒå˜èªé•·ã®åŠåˆ†ä»¥ä¸Šã‚’å ã‚ã‚‹å ´åˆã¯ä¸è‡ªç„¶ã¨ã¿ãªã™
        if foreignSoundCount > text.count / 2 {
            AppLogger.shared.debug("éåº¦ãªå¤–æ¥èªéŸ³æ¤œå‡º: \(text)")
            return true
        }
        
        return false
    }
    
    /// ç„¡åŠ¹ãªæ–‡å­—ã‚’å«ã‚€ã‹ãƒã‚§ãƒƒã‚¯
    private func hasInvalidCharacters(_ text: String) -> Bool {
        // ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»é•·éŸ³ç¬¦ãƒ»å°æ›¸ãæ–‡å­—ã®æ­£ç¢ºãªå®šç¾©
        let hiraganaRange = CharacterSet(charactersIn: "\u{3041}...\u{3096}")  // ã²ã‚‰ãŒãªç¯„å›²
        let katakanaRange = CharacterSet(charactersIn: "\u{30A1}...\u{30F6}")  // ã‚«ã‚¿ã‚«ãƒŠç¯„å›²
        let additionalChars = CharacterSet(charactersIn: "ãƒ¼ãƒ»ã€ã€‚")  // é•·éŸ³ç¬¦ãƒ»ä¸­ç‚¹ãƒ»å¥èª­ç‚¹
        
        let validCharacters = hiraganaRange
            .union(katakanaRange)
            .union(additionalChars)
        
        for scalar in text.unicodeScalars {
            if !validCharacters.contains(scalar) {
                // è‹±æ•°å­—ã‚„æ˜ã‚‰ã‹ã«ç„¡åŠ¹ãªæ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯
                let char = String(scalar)
                if char.range(of: "[a-zA-Z0-9]", options: .regularExpression) != nil {
                    AppLogger.shared.debug("ç„¡åŠ¹ãªæ–‡å­—æ¤œå‡ºï¼ˆè‹±æ•°å­—ï¼‰: '\(char)' in '\(text)'")
                    return true
                }
                
                // åˆ¶å¾¡æ–‡å­—ã‚„ãã®ä»–ã®ç„¡åŠ¹æ–‡å­—
                if scalar.value < 32 || (scalar.value >= 127 && scalar.value < 160) {
                    AppLogger.shared.debug("ç„¡åŠ¹ãªæ–‡å­—æ¤œå‡ºï¼ˆåˆ¶å¾¡æ–‡å­—ï¼‰: '\(char)' in '\(text)'")
                    return true
                }
                
                AppLogger.shared.debug("æ–‡å­—ãƒã‚§ãƒƒã‚¯: '\(char)' (U+\(String(scalar.value, radix: 16).uppercased())) - è¨±å¯")
            }
        }
        
        return false
    }
}

// MARK: - SFSpeechRecognizerDelegate

extension SpeechRecognitionManager: SFSpeechRecognizerDelegate {
    public func speechRecognizer(_ speechRecognizer: SFSpeechRecognizer, availabilityDidChange available: Bool) {
        AppLogger.shared.debug("éŸ³å£°èªè­˜åˆ©ç”¨å¯èƒ½æ€§å¤‰æ›´: \(available)")
        DispatchQueue.main.async {
            self.updateAvailability()
        }
    }
}

// MARK: - Error Types

public enum SpeechRecognitionError: Error, LocalizedError {
    case recognitionRequestCreationFailed
    case speechRecognizerUnavailable
    
    public var errorDescription: String? {
        switch self {
        case .recognitionRequestCreationFailed:
            return "éŸ³å£°èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .speechRecognizerUnavailable:
            return "éŸ³å£°èªè­˜æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
        }
    }
}
